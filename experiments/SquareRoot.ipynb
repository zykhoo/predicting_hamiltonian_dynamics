{"cells":[{"cell_type":"markdown","metadata":{"id":"IBMJDLxHG5qy"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30637,"status":"ok","timestamp":1649646032551,"user":{"displayName":"Khoo Zi-Yu","userId":"01763969606877785000"},"user_tz":-480},"id":"o7TO8yO_B2Qf","outputId":"ef614516-2abf-4a6c-813b-83ccffbb0740"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scipy==1.6.3\n","  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n","\u001b[K     |████████████████████████████████| 27.4 MB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.6.3) (1.21.5)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed scipy-1.6.3\n","Collecting scikit_optimize==0.8.1\n","  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 3.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit_optimize==0.8.1) (1.21.5)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit_optimize==0.8.1) (1.6.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_optimize==0.8.1) (1.1.0)\n","Collecting pyaml>=16.9\n","  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit_optimize==0.8.1) (1.0.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit_optimize==0.8.1) (3.13)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit_optimize==0.8.1) (3.1.0)\n","Installing collected packages: pyaml, scikit-optimize\n","Successfully installed pyaml-21.10.1 scikit-optimize-0.8.1\n","Collecting scikit_learn==0.24.2\n","  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n","\u001b[K     |████████████████████████████████| 22.3 MB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==0.24.2) (1.21.5)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==0.24.2) (1.6.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==0.24.2) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==0.24.2) (1.1.0)\n","Installing collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n","Successfully installed scikit-learn-0.24.2\n","Cloning into 'predicting_hamiltonian_dynamics'...\n","remote: Enumerating objects: 709, done.\u001b[K\n","remote: Counting objects: 100% (709/709), done.\u001b[K\n","remote: Compressing objects: 100% (650/650), done.\u001b[K\n","remote: Total 709 (delta 358), reused 0 (delta 0), pack-reused 0\u001b[K\n","Receiving objects: 100% (709/709), 188.19 KiB | 594.00 KiB/s, done.\n","Resolving deltas: 100% (358/358), done.\n"]}],"source":["!pip install scipy==1.6.3\n","!pip install scikit_optimize==0.8.1\n","!pip install scikit_learn==0.24.2\n","! git clone https://github.com/zykhoo/predicting_hamiltonian_dynamics.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31368,"status":"ok","timestamp":1649646063885,"user":{"displayName":"Khoo Zi-Yu","userId":"01763969606877785000"},"user_tz":-480},"id":"3t1tKKAfONRF","outputId":"d212066f-7ea2-4b80-b90d-a13c2fd72992"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"lIv4hj16MlK5"},"source":["# Run all"]},{"cell_type":"code","source":["\"\"\"# Experiment setup\"\"\"\n","\n","import numpy as np\n","\n","experiment,sys,dim = \"NN\",\"squareroot\",2\n","\n","H = lambda x: np.sqrt(x[0]**4 + x[1]**2+1)\n","f1 = lambda x: (x[1])/np.sqrt(x[0]**4 + x[1]**2 +1) # dH/dy\n","f2 = lambda x: -2*(x[0]**3)/np.sqrt(x[0]**4 + x[1]**2 +1) # -dH/dx\n","spacedim = [(0.,2.),(0.,2.)]\n","h= 0.1\n","x0, H0 = 0.,1.\n","initialcon = [64, 128, 256, 512, 1024]\n","LR = 0.001\n","diagdist = np.sum(np.square(np.asarray([spacedim[0][0], spacedim[0][1]]), np.asarray([spacedim[1][0], spacedim[1][1]])))\n","epsilon = 0.1\n","fvector = lambda x: np.asarray([f1(x), f2(x)])\n","\n","\"\"\"# Test dataset creation\"\"\"\n","\n","from predicting_hamiltonian_dynamics import groundtruth_2dim\n","from tqdm import tqdm\n","import time \n","\n","evaluation_length_long = 50\n","evaluation_length_one = 1\n","\n","xxlong,yylong = np.linspace(spacedim[0][0], spacedim[0][1], 5), np.linspace(spacedim[1][0], spacedim[1][1], 5)\n","xlong,ylong = np.meshgrid(xxlong,yylong)\n","xxshort,yyshort = np.linspace(spacedim[0][0], spacedim[0][1], 20), np.linspace(spacedim[1][0], spacedim[1][1], 20)\n","xshort,yshort = np.meshgrid(xxshort,yyshort)\n","\n","trajectories_groundtruth_start_long = np.expand_dims(groundtruth_2dim.classicTrajectory(np.asarray([[0.4],[0.]]),f1,f2,h = 0.1,N=evaluation_length_long,n_h = 1),0)\n","for i in tqdm(np.expand_dims(np.c_[np.ravel(xlong),np.ravel(ylong)],2)):\n","  results_200 = np.expand_dims(groundtruth_2dim.classicTrajectory(i,f1,f2,h = 0.1,N=evaluation_length_long,n_h = 1),0)\n","  trajectories_groundtruth_start_long = np.vstack((trajectories_groundtruth_start_long, results_200))\n","trajectories_groundtruth_start_long.shape # output no., start and final, p and q, full traj\n","\n","trajectories_groundtruth_start_short = np.expand_dims(groundtruth_2dim.classicTrajectory(np.asarray([[0.4],[0.]]),f1,f2,h = 0.1,N=evaluation_length_one,n_h = 1),0)\n","for i in tqdm(np.expand_dims(np.c_[np.ravel(xshort),np.ravel(yshort)],2)):\n","  results_200 = np.expand_dims(groundtruth_2dim.classicTrajectory(i,f1,f2,h = 0.1,N=evaluation_length_one,n_h = 1),0)\n","  trajectories_groundtruth_start_short = np.vstack((trajectories_groundtruth_start_short, results_200))\n","trajectories_groundtruth_start_short.shape # output no., start and final, p and q, full traj\n","\n","within_array = groundtruth_2dim.get_within_array(trajectories_groundtruth_start_long, spacedim)"],"metadata":{"id":"m2hqGpQ0QVkG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649646065036,"user_tz":-480,"elapsed":1157,"user":{"displayName":"Khoo Zi-Yu","userId":"01763969606877785000"}},"outputId":"bd8400be-87b7-4bab-bdd6-aff6b8412269"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:00<00:00, 47.86it/s]\n","100%|██████████| 400/400 [00:00<00:00, 1403.79it/s]\n"]}]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/SSI/Baseline v2/synthetic systems (upload)/'"],"metadata":{"id":"NZ6hNpeUQbC6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1BTYI8u5-KPiTn9noi-wceHgS3X08q6S1"},"id":"yxgIfXLQMmKB","outputId":"a233a299-5e99-437f-c013-71d7b078ee19"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from predicting_hamiltonian_dynamics.models import NN_2dim\n","from predicting_hamiltonian_dynamics.models import GP_2dim\n","from predicting_hamiltonian_dynamics.models import PINN_2dim\n","from predicting_hamiltonian_dynamics.models import PIGP_2dim\n","\n","\n","for i in range(20):\n","  seed = i\n","  np.random.seed(seed=seed)\n","  for ini in initialcon: \n","\n","    start, final = groundtruth_2dim.CreateTrainingDataTrajClassicIntRandom(1,ini,spacedim,h,f1,f2,seed = seed,n_h = 1)\n","\n","    delta = start.copy()\n","    delta[0,:] = f1(start)\n","    delta[1,:] = f2(start)\n","\n","    \"\"\"# NN\"\"\"\n","\n","    from predicting_hamiltonian_dynamics.models import NN_2dim\n","    import torch\n","\n","    if torch.cuda.is_available():\n","      device=torch.device('cuda')\n","    else:\n","      device=torch.device('cpu')\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","\n","    wholemat, evalmat = NN_2dim.data_preprocessing(start, delta, device)\n","\n","    import torch.optim as optim\n","    import time \n","\n","    net = NN_2dim.Net(dim,16,dim)\n","    starttime = time.time() \n","    net = NN_2dim.train(net, wholemat, evalmat, optimizer=optim.Adam(net.parameters(), lr=LR), batchsize=10, iter=1600, )\n","    traintime = time.time()-starttime\n","\n","\n","    from tqdm import tqdm\n","    from predicting_hamiltonian_dynamics.models import NN_2dim\n","    from predicting_hamiltonian_dynamics import metrics\n","\n","\n","    MSE_long, time_long, MSE_long_naive, time_long_naive, MSE_within, time_within, MSE_within_naive, time_within_naive, MSE_onestep, time_onestep, MSE_vectorfield, time_vectorfield, _, _ = NN_2dim.compute_metrics_NN(net, h, diagdist, xshort, yshort, xlong, ylong, evaluation_length_long, within_array, trajectories_groundtruth_start_long, trajectories_groundtruth_start_short, fvector)\n","\n","    file_object = open(path + 'SquareRoot_random.txt', 'a')\n","    file_object.write('NN, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s \\n' %(ini, seed, traintime, MSE_long, time_long, MSE_long_naive, time_long_naive, MSE_within, time_within, MSE_within_naive, time_within_naive, MSE_onestep, time_onestep, MSE_vectorfield, time_vectorfield))\n","    file_object.close()\n","\n","\n","    \"\"\"# GP\"\"\"\n","\n","    from sklearn.gaussian_process import GaussianProcessRegressor\n","    from sklearn.gaussian_process.kernels import RBF\n","    from sklearn import preprocessing\n","\n","    output = delta\n","    scaler = preprocessing.MinMaxScaler()\n","    input = scaler.fit_transform(start.transpose())\n","    kernel = 1 * RBF(length_scale=2., length_scale_bounds=\"fixed\")\n","    gaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=0, optimizer = None, random_state = seed)\n","    starttime = time.time() \n","    gaussian_process.fit(input, output.transpose())\n","    traintime = time.time()-starttime\n","    gaussian_process.predict(scaler.transform([[0.7,0.8]]))\n","\n","    MSE_long, time_long, MSE_long_naive, time_long_naive, MSE_within, time_within, MSE_within_naive, time_within_naive, MSE_onestep, time_onestep, MSE_vectorfield, time_vectorfield, _, _ = GP_2dim.compute_metrics_GP(gaussian_process, scaler, h, diagdist, xshort, yshort, xlong, ylong, evaluation_length_long, within_array, trajectories_groundtruth_start_long, trajectories_groundtruth_start_short, fvector)\n","\n","    file_object = open(path + 'SquareRoot_random.txt', 'a')\n","    file_object.write('GP, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s \\n' %(ini, seed, traintime, MSE_long, time_long, MSE_long_naive, time_long_naive, MSE_within, time_within, MSE_within_naive, time_within_naive, MSE_onestep, time_onestep, MSE_vectorfield, time_vectorfield))\n","    file_object.close()\n","\n","\n","    \"\"\"# PINN\"\"\"\n","\n","    from predicting_hamiltonian_dynamics.models import PINN_2dim\n","    import torch\n","\n","    if torch.cuda.is_available():\n","      device=torch.device('cuda')\n","    else:\n","      device=torch.device('cpu')\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    wholemat, evalmat = PINN_2dim.data_preprocessing(start, delta,device)\n","    net=PINN_2dim.Net(dim,16,1)\n","    starttime = time.time()\n","    net,avg_vallosses,avg_lossli,avg_f1li,avg_f2li,avg_f3li,avg_f4li=PINN_2dim.train(net,bs=10,num_epoch=5000,initial_conditions=initialcon,device=device,\n","                                                                                    wholemat=wholemat,evalmat=evalmat,x0=x0,H0=H0,dim=dim,LR=LR,patience=500,c1=1,c2=1,c3=1,c4=1)\n","    traintime = time.time()-starttime\n","\n","    MSE_long, time_long, MSE_long_naive, time_long_naive, MSE_within, time_within, MSE_within_naive, time_within_naive, MSE_onestep, time_onestep, MSE_vectorfield, time_vectorfield, _, _ = PINN_2dim.compute_metrics_PINN(net, device, h, diagdist, xshort, yshort, xlong, ylong, evaluation_length_long, within_array, trajectories_groundtruth_start_long, trajectories_groundtruth_start_short, fvector)\n","    \n","    file_object = open(path + 'SquareRoot_random.txt', 'a')\n","    file_object.write('PINN, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s \\n' %(ini, seed, traintime, MSE_long, time_long, MSE_long_naive, time_long_naive, MSE_within, time_within, MSE_within_naive, time_within_naive, MSE_onestep, time_onestep, MSE_vectorfield, time_vectorfield))\n","    file_object.close()\n","\n","    \"\"\"# PIGP\"\"\"\n","\n","    from predicting_hamiltonian_dynamics.models import PIGP_2dim\n","    GP = PIGP_2dim.BertalanGP()\n","    starttime = time.time()\n","    GP.train(start,delta,h)\n","    traintime = time.time()-starttime\n","\n","    MSE_long, time_long, MSE_long_naive, time_long_naive, MSE_within, time_within, MSE_within_naive, time_within_naive, MSE_onestep, time_onestep, MSE_vectorfield, time_vectorfield, _, _ = PIGP_2dim.compute_metrics_PIGP(GP, h, diagdist, xshort, yshort, xlong, ylong, evaluation_length_long, within_array, trajectories_groundtruth_start_long, trajectories_groundtruth_start_short, fvector)\n","\n","    file_object = open(path + 'SquareRoot_random.txt', 'a')\n","    file_object.write('PIGP, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s \\n' %(ini, seed, traintime, MSE_long, time_long, MSE_long_naive, time_long_naive, MSE_within, time_within, MSE_within_naive, time_within_naive, MSE_onestep, time_onestep, MSE_vectorfield, time_vectorfield))\n","    file_object.close()\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"SquareRoot.ipynb","provenance":[],"authorship_tag":"ABX9TyMyKNl+sLzeQnaEjmXUlzD7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}